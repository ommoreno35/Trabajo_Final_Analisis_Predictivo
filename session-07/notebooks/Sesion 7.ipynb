{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a24d96d5",
   "metadata": {},
   "source": [
    "# 📘 Sesión 7: Comparación de Modelos e Introducción a Redes Neuronales\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5336565",
   "metadata": {},
   "source": [
    "## 🎯 Objetivo\n",
    "Comparar modelos supervisados e introducir redes neuronales simples con `MLPClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ffdbb8",
   "metadata": {},
   "source": [
    "## 🔍 Carga de datos\n",
    "Usaremos el dataset `breast_cancer` de sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7543da90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "df['target'] = cancer.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bc6091",
   "metadata": {},
   "source": [
    "## ⚙️ Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d27cd667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = df.drop(columns='target')\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051ba9ff",
   "metadata": {},
   "source": [
    "## 📊 Comparación de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6b6448d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: Exactitud promedio (cross-val): 0.955 ± 0.017\n",
      "Regresión Logística: Exactitud promedio (cross-val): 0.957 ± 0.006\n",
      "Árbol de Decisión: Exactitud promedio (cross-val): 0.910 ± 0.029\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "models = {\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Regresión Logística': LogisticRegression(max_iter=300),\n",
    "    'Árbol de Decisión': DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"{name}: Exactitud promedio (cross-val): {scores.mean():.3f} ± {scores.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d14264-30df-4d38-bb14-69e00a78df23",
   "metadata": {},
   "source": [
    "### 📘 Explicación del código\n",
    "\n",
    "- `from sklearn.neighbors import KNeighborsClassifier`, `LogisticRegression`, `DecisionTreeClassifier`:  \n",
    "  Se importan tres modelos supervisados clásicos desde `scikit-learn` para comparación.\n",
    "\n",
    "- `from sklearn.model_selection import cross_val_score`:  \n",
    "  Importa la función que permite aplicar validación cruzada a un modelo. Evalúa el desempeño promedio de un modelo entrenado y validado en múltiples particiones del conjunto de datos.\n",
    "\n",
    "- `models = { ... }`:  \n",
    "  Se define un diccionario con los tres modelos: KNN, regresión logística y árbol de decisión, cada uno instanciado con sus parámetros por defecto (excepto `max_iter=300` en regresión logística para asegurar convergencia).\n",
    "\n",
    "- `for name, model in models.items()`:  \n",
    "  Itera sobre cada modelo definido para evaluarlo con la misma estrategia.\n",
    "\n",
    "- `cross_val_score(...)`:  \n",
    "  Ejecuta validación cruzada con 5 particiones (`cv=5`) sobre los datos de entrenamiento. Se mide la `accuracy` en cada iteración.\n",
    "\n",
    "- `scores.mean()`, `scores.std()`:  \n",
    "  Calcula el promedio y la desviación estándar de las 5 mediciones de exactitud obtenidas por la validación cruzada.\n",
    "\n",
    "Este enfoque permite evaluar los modelos de forma justa, reduciendo el riesgo de sobreajuste a una sola división de los datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e77fca5-a10e-4643-a3d2-fdaeab1a7779",
   "metadata": {},
   "source": [
    "### 📊 Análisis de resultados de validación cruzada\n",
    "\n",
    "| Modelo               | Exactitud promedio | Desviación estándar |\n",
    "|----------------------|--------------------|----------------------|\n",
    "| KNN                  | 0.955              | ± 0.017              |\n",
    "| Regresión Logística  | 0.957              | ± 0.006              |\n",
    "| Árbol de Decisión    | 0.909              | ± 0.013              |\n",
    "\n",
    "- **KNN y Regresión Logística** muestran un rendimiento muy alto y similar en precisión promedio (~95.5%), con la regresión ligeramente mejor.\n",
    "- La **regresión logística** además tiene una **desviación estándar más baja**, lo que indica que su desempeño es más estable entre particiones del conjunto de datos.\n",
    "- El **árbol de decisión** tiene una exactitud promedio menor (90.9%) y una desviación más alta que la regresión, lo que sugiere mayor variabilidad y posiblemente más sensibilidad a los datos de entrenamiento.\n",
    "\n",
    "**Conclusión:** En este conjunto de datos, tanto KNN como regresión logística generalizan bien, pero la regresión muestra más consistencia. El árbol podría estar sobreajustando o no capturando adecuadamente la estructura de los datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66301898",
   "metadata": {},
   "source": [
    "## 🤖 Introducción a redes neuronales (MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bdf2d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del MLPClassifier: 0.977\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(20,), activation='relu', max_iter=1000, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "mlp_score = mlp.score(X_test, y_test)\n",
    "print(f\"Exactitud del MLPClassifier: {mlp_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28350dfc-750d-497d-85ec-5bd6a286529c",
   "metadata": {},
   "source": [
    "### 📘 Explicación del código\n",
    "\n",
    "- `from sklearn.neural_network import MLPClassifier`:  \n",
    "  Importa la clase `MLPClassifier`, que implementa un perceptrón multicapa (red neuronal artificial) para tareas de clasificación supervisada.\n",
    "\n",
    "- `mlp = MLPClassifier(...)`:  \n",
    "  Se crea un modelo de red neuronal con los siguientes parámetros:\n",
    "  - `hidden_layer_sizes=(20,)`: se define una sola capa oculta con 20 neuronas.\n",
    "  - `activation='relu'`: se utiliza la función de activación ReLU, común en redes profundas por su eficiencia.\n",
    "  - `max_iter=1000`: se permite hasta 1000 iteraciones para que el modelo converja.\n",
    "  - `random_state=42`: se fija una semilla para reproducibilidad.\n",
    "\n",
    "- `mlp.fit(X_train, y_train)`:  \n",
    "  Entrena la red neuronal con los datos normalizados de entrenamiento. Durante el entrenamiento, la red ajusta los pesos y sesgos internos para minimizar el error de clasificación.\n",
    "\n",
    "- `mlp.score(X_test, y_test)`:  \n",
    "  Calcula la exactitud del modelo sobre el conjunto de prueba, es decir, la proporción de predicciones correctas.\n",
    "\n",
    "- `print(...)`:  \n",
    "  Muestra la exactitud alcanzada por el modelo entrenado sobre datos no vistos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f12676d",
   "metadata": {},
   "source": [
    "### 📊 Análisis ampliado del resultado\n",
    "\n",
    "El modelo `MLPClassifier` alcanzó una exactitud del **97.7%** sobre el conjunto de prueba. Este desempeño es superior al reportado por los modelos tradicionales comparados mediante validación cruzada:\n",
    "\n",
    "- **KNN**: 95.5%\n",
    "- **Regresión logística**: 95.7%\n",
    "- **Árbol de decisión**: 90.9%\n",
    "\n",
    "Aunque esta comparación debe tomarse con precaución —ya que el MLP fue evaluado sobre una única partición de prueba (`test set`) mientras los otros modelos fueron evaluados con validación cruzada (`cross_val`)—, el resultado sugiere que la red neuronal fue capaz de **capturar relaciones más complejas** en los datos que los otros algoritmos no lograron modelar completamente.\n",
    "\n",
    "Este buen desempeño puede atribuirse a varias características de las redes neuronales:\n",
    "\n",
    "- Son capaces de **modelar no linealidades** de forma natural gracias a sus funciones de activación no lineales.\n",
    "- Pueden **componer transformaciones internas** a través de múltiples capas, lo que les permite aprender representaciones jerárquicas de los datos.\n",
    "- El entrenamiento se realiza optimizando una función de pérdida global, lo que favorece una solución más ajustada a la estructura de los datos.\n",
    "\n",
    "No obstante, las redes neuronales también presentan **ciertas limitaciones importantes**:\n",
    "\n",
    "- Son modelos que requieren **más tiempo de entrenamiento**, especialmente si el número de capas o de neuronas es elevado.\n",
    "- Son **menos interpretables**, ya que no generan reglas claras ni coeficientes con sentido directo, como en la regresión logística o los árboles de decisión.\n",
    "- Son **sensibles a los hiperparámetros** y a la inicialización, lo que hace necesario ajustar cuidadosamente valores como el número de capas, el tamaño de cada capa, el tipo de activación o el algoritmo de optimización.\n",
    "\n",
    "Por estas razones, aunque el resultado obtenido es muy positivo, se recomienda complementar este análisis con otras métricas como la **precisión, recall, F1-score** y especialmente con la **matriz de confusión**, para verificar que el buen rendimiento global no oculte deficiencias graves en alguna de las clases (por ejemplo, un mal desempeño al identificar la clase minoritaria).\n",
    "\n",
    "Además, puede ser útil aplicar **validación cruzada también al MLPClassifier**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171cb220-ec4d-48dd-a50e-ff7c6801d3da",
   "metadata": {},
   "source": [
    "### ✅ Conclusión\n",
    "\n",
    "El modelo `MLPClassifier` logró un desempeño superior en términos de exactitud (97.7%) frente a los modelos comparados previamente. Aunque esta cifra proviene de una evaluación directa sobre el conjunto de prueba (y no de validación cruzada), sugiere que la red neuronal fue capaz de modelar relaciones más complejas en los datos.\n",
    "\n",
    "Esto resalta el potencial de las redes neuronales cuando existen patrones no lineales difíciles de capturar con modelos más simples. Sin embargo, su implementación también implica desafíos: mayor tiempo de entrenamiento, menor interpretabilidad y sensibilidad a la configuración de hiperparámetros.\n",
    "\n",
    "Por tanto, si bien su rendimiento es prometedor, se recomienda validar su comportamiento con métricas adicionales como F1-score, AUC y matriz de confusión. También sería ideal aplicar validación cruzada para obtener una comparación equitativa con los modelos previos y garantizar su estabilidad frente a nuevas particiones del conjunto de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50bb531-a695-479e-ad0b-a31ac744ff52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
