{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57924ff8",
   "metadata": {},
   "source": [
    "# 🧠 Clasificación, Limpieza y Evaluación de Datos con Explicaciones Completas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05425b1e",
   "metadata": {},
   "source": [
    "## 📂 Cargar base de datos desde ruta verificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4338fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "ruta = '../../datos/dataset_ejemplo_1300.csv'\n",
    "if not os.path.exists(ruta):\n",
    "    raise FileNotFoundError(f'❌ El archivo no se encuentra en: {ruta}')\n",
    "df_raw = pd.read_csv(ruta)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3409ee99",
   "metadata": {},
   "source": [
    "## 🎯 Crear variables `Alta_conectividad` y `Nivel_conectividad`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9436a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['Alta_conectividad'] = (df_raw['Horas_Internet'] > 3.5).astype(int)\n",
    "\n",
    "def clasificar_conectividad(horas):\n",
    "    if horas <= 1:\n",
    "        return 0\n",
    "    elif horas <= 3.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df_raw['Nivel_conectividad'] = df_raw['Horas_Internet'].apply(clasificar_conectividad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd49c519",
   "metadata": {},
   "source": [
    "## 🧼 Imputación de valores faltantes con `SimpleImputer`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7bfd72",
   "metadata": {},
   "source": [
    "| Estrategia         | Qué hace                                       | Cuándo usarla                                     | Ejemplo                                                                 |\n",
    "|--------------------|-----------------------------------------------|---------------------------------------------------|-------------------------------------------------------------------------|\n",
    "| `'mean'`           | Sustituye con la media                        | Datos numéricos sin outliers                      | Edad: `[25, 28, NaN, 22, 30] → NaN = 26.25`                             |\n",
    "| `'median'`         | Sustituye con la mediana                      | Datos numéricos con outliers                      | Ingreso: `[1000, 1200, NaN, 8000, 1100] → NaN = 1150`                   |\n",
    "| `'most_frequent'`  | Sustituye con el valor más común (moda)       | Datos categóricos                                 | Género: `['F', 'M', NaN, 'F'] → NaN = 'F'`                              |\n",
    "| `'constant'`       | Sustituye con un valor definido por el usuario| Para normalizar o identificar nulos               | Ciudad: `['Bogotá', NaN] → fill_value='Desconocida' → NaN = 'Desconocida'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e6c298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "df_clean = df_raw.copy()\n",
    "imputer_edad = SimpleImputer(strategy='median')\n",
    "df_clean['Edad'] = imputer_edad.fit_transform(df_clean[['Edad']])\n",
    "imputer_ingreso = SimpleImputer(strategy='mean')\n",
    "df_clean['Ingreso'] = imputer_ingreso.fit_transform(df_clean[['Ingreso']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8d3268",
   "metadata": {},
   "source": [
    "## 🔣 Codificación de variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda880d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.get_dummies(df_clean, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d7dc4f",
   "metadata": {},
   "source": [
    "## 📏 Escalado con `MinMaxScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ee095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "cols_numericas = df_clean.select_dtypes(include=['int64', 'float64']).columns\n",
    "scaler = MinMaxScaler()\n",
    "df_clean[cols_numericas] = scaler.fit_transform(df_clean[cols_numericas])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6a5960",
   "metadata": {},
   "source": [
    "## ✅ Filtrar solo columnas numéricas antes del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c43708",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xc = df_clean.drop(columns=['Alta_conectividad'])\n",
    "Xc = Xc.select_dtypes(include=['int64', 'float64'])\n",
    "yc = df_clean['Alta_conectividad']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77d0291",
   "metadata": {},
   "source": [
    "## 🤖 Entrenamiento del modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace91cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(Xc, yc, test_size=0.3, random_state=42)\n",
    "model_after = LogisticRegression(max_iter=200)\n",
    "model_after.fit(Xc_train, yc_train)\n",
    "yc_pred = model_after.predict(Xc_test)\n",
    "acc_after = accuracy_score(yc_test, yc_pred)\n",
    "print('✅ Exactitud del modelo:', round(acc_after, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f24a531",
   "metadata": {},
   "source": [
    "## 📊 Evaluación del modelo con métricas adicionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0def13a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(\"📌 Matriz de confusión:\")\n",
    "print(confusion_matrix(yc_test, yc_pred))\n",
    "\n",
    "print(\"\\n📌 Reporte de clasificación:\")\n",
    "print(classification_report(yc_test, yc_pred))\n",
    "\n",
    "print(\"\\n📌 Distribución de clases en y_test:\")\n",
    "print(yc_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80409f1",
   "metadata": {},
   "source": [
    "\n",
    "## 📈 Interpretación de resultados del modelo\n",
    "\n",
    "### 📌 Matriz de confusión:\n",
    "\n",
    "```\n",
    "[[246   0]\n",
    " [  0 144]]\n",
    "```\n",
    "\n",
    "Esto representa cómo el modelo clasificó los datos de prueba para la variable `Alta_conectividad`:\n",
    "\n",
    "- `246`: casos correctamente predichos como clase 0 (baja conectividad).\n",
    "- `144`: casos correctamente predichos como clase 1 (alta conectividad).\n",
    "- `0`: no hubo errores de clasificación. ¡Predicción perfecta!\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 Reporte de clasificación:\n",
    "\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      1.00      1.00       246\n",
    "         1.0       1.00      1.00      1.00       144\n",
    "\n",
    "    accuracy                           1.00       390\n",
    "   macro avg       1.00      1.00      1.00       390\n",
    "weighted avg       1.00      1.00      1.00       390\n",
    "```\n",
    "\n",
    "**Significado de las métricas**:\n",
    "- **Precision**: qué tan precisas fueron las predicciones positivas del modelo.\n",
    "- **Recall**: qué tanto logró detectar de las clases verdaderas.\n",
    "- **F1-score**: promedio ponderado entre precisión y recall.\n",
    "\n",
    "Todas estas métricas son perfectas (1.00), lo que indica **predicción sin errores**.\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 Distribución de clases en `y_test`:\n",
    "\n",
    "```\n",
    "Alta_conectividad\n",
    "0.0    0.630769\n",
    "1.0    0.369231\n",
    "```\n",
    "\n",
    "Esto significa:\n",
    "- El 63% de los casos eran clase 0.\n",
    "- El 37% eran clase 1.\n",
    "\n",
    "La distribución está suficientemente equilibrada, lo cual **valida que el modelo no está simplemente prediciendo la clase dominante**.\n",
    "\n",
    "---\n",
    "\n",
    "✅ **Conclusión**:\n",
    "El modelo obtuvo una predicción perfecta sin errores. Esto puede ser legítimo si hay variables predictoras altamente informativas como `Horas_Internet`. Para validar mejor, se incluyó evaluación cruzada en la siguiente celda.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30febade",
   "metadata": {},
   "source": [
    "## 🧪 Validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0a2b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(max_iter=200), Xc, yc, cv=5)\n",
    "print(\"📈 Resultados de validación cruzada:\", scores)\n",
    "print(\"Promedio:\", scores.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
